{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Sets\n",
    "\n",
    "This is an experiment to check if BS work well for our companion recommendation use case. The implementation that we are going to use is https://github.com/MaLL-UFSCar/bayessets. Be sure to install it via `!pip install git+https://github.com/MaLL-UFSCar/bayessets.git`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "from scipy import sparse\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_sparsity(array):\n",
    "    num_total = total_elems(array)\n",
    "    num_non_zero = zero_elems(array, num_total)\n",
    "    sparsity = num_non_zero/num_total\n",
    "    print(\"Sparsity of matrix is = {}\".format(sparsity))\n",
    "    return sparsity\n",
    "\n",
    "\n",
    "def zero_elems(array, num_total):\n",
    "    non_zero = numpy.count_nonzero(array)\n",
    "    return num_total-non_zero\n",
    "\n",
    "\n",
    "def total_elems(array):\n",
    "    shape = array.shape\n",
    "    return shape[0]*shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('package-to-id-dict-without-trans.json', 'r') as f:\n",
    "    pack_to_id = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('manifest-to-id-without-trans.pickle', 'rb') as f:\n",
    "    man_to_id = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16101"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "man_to_id.get(frozenset(['django']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = len(man_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = len(pack_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66018"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18796"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1 - Training the model\n",
    "\n",
    "Here we define a sparse matrix of manifests (users) x packages (items). Here, we mark those entries as 1 for the manifests that contain those packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_matrix = numpy.zeros((users, items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item_list, user in man_to_id.items():\n",
    "    for item in item_list:\n",
    "        rating_matrix[user][pack_to_id.get(item)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity of matrix is = 0.9996093746247605\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9996093746247605"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_sparsity(rating_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_matrix[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_rating_matrix = sparse.csr_matrix(rating_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now transpose the matrix here i.e make it items x users. The reason being the following:\n",
    "\n",
    "If you consider that each package is an item that could be recommended, then it works like a recommender system. If you consider that each feature is a user, then it works like a collaborative filter RS. So, if you had kept the original input, then we will be querying the model to find similar users rather than items. \n",
    "\n",
    "Well, interesting thought here: Can we combine both the approaches to say that these are the items and these are the users that are similar and combine that information to generate the final set of recommendations? That can help us filter the recommendations better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_rating_matrix = sparse_rating_matrix.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10x66018 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 48037 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_rating_matrix[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bayessets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We just pass the sparse rating matrix to the model\n",
    "\n",
    "model = bayessets.BernoulliBayesianSet(sparse_rating_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's save the trained model\n",
    "\n",
    "with open('Bayesian_Sets.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2 - Scoring the model\n",
    "\n",
    "Here we will see how the model behaves based on different stack inputs and personas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load the model\n",
    "\n",
    "with open('Bayesian_Sets.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('id-to-package-dict-without-trans.json', 'r') as f:\n",
    "    id_to_pack = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_packages_from_id(package_ids):\n",
    "    package_list = list()\n",
    "    for i in package_ids:\n",
    "        package = id_to_pack.get(str(i))\n",
    "        package_list.append(package)\n",
    "    return package_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_input_to_package_ids(input_stack):\n",
    "    package_id_list = list()\n",
    "    for package in input_stack:\n",
    "        package_id = pack_to_id.get(package)\n",
    "        if package_id is not None:\n",
    "            package_id_list.append(package_id)\n",
    "    return package_id_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's see how the model behaves for stacks that have tensorflow, keras in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248\n"
     ]
    }
   ],
   "source": [
    "# Let's get started\n",
    "count = 0\n",
    "l = []\n",
    "for item in man_to_id.items():\n",
    "    if 'tensorflow' in item[0] and 'keras' in item[0]:\n",
    "        count+=1\n",
    "        l.append(item[0])\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we have 248 stacks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[frozenset({'lxml', 'keras', 'tensorflow'}), frozenset({'keras', 'tensorflow', 'midi'}), frozenset({'tqdm', 'keras', 'docopt', 'tensorflow', 'opencv-python', 'python-resize-image', 'logger', 'scikit-image', 'hdfs3'}), frozenset({'dill', 'keras', 'tensorflow', 'matplotlib', 'scikit-learn'}), frozenset({'pykitti', 'packaging', 'pip', 'keras', 'unrealcv', 'transforms3d', 'pymongo', 'xxhash', 'tensorflow'}), frozenset({'tqdm', 'theano', 'keras', 'pygame', 'sgf', 'tensorflow', 'scikit-learn'}), frozenset({'sphinx-gallery', 'nbsphinx', 'keras', 'pillow', 'tensorflow', 'cython', 'ipykernel', 'scikit-learn'}), frozenset({'keras', 'pillow', 'dill', 'tensorflow'}), frozenset({'simplegeneric', 'certifi', 'werkzeug', 'cycler', 'jupyter', 'pytz', 'matplotlib', 'jupyter-console', 'wcwidth', 'imageio', 'olefile', 'pyparsing', 'pillow', 'pathlib2', 'html5lib', 'tqdm', 'singledispatch', 'theano', 'keras', 'moviepy', 'tensorflow', 'backports-shutil-get-terminal-size', 'scandir', 'subprocess32', 'pbr', 'backports-abc'}), frozenset({'keras', 'pillow', 'tensorflow'})]\n"
     ]
    }
   ],
   "source": [
    "# Let's see which users have that\n",
    "x = l[:10]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stack is:  frozenset({'lxml', 'keras', 'tensorflow'})\n",
      "========================================\n",
      "Recommendations are:  {'tqdm', 'theano', 'sklearn', 'tensorflow-tensorboard', 'opencv-python', 'jupyter', 'scikit-learn'}\n",
      "========================================\n",
      "Stack is:  frozenset({'keras', 'tensorflow', 'midi'})\n",
      "========================================\n",
      "Recommendations are:  {'theano', 'tensorflow-gpu', 'sklearn', 'tensorflow-tensorboard', 'opencv-python', 'jupyter', 'scikit-image', 'scikit-learn'}\n",
      "========================================\n",
      "Stack is:  frozenset({'tqdm', 'keras', 'docopt', 'tensorflow', 'opencv-python', 'python-resize-image', 'logger', 'scikit-image', 'hdfs3'})\n",
      "========================================\n",
      "Recommendations are:  {'dockerpty', 'tensorflow-tensorboard', 'tensorflow-gpu', 'theano'}\n",
      "========================================\n",
      "Stack is:  frozenset({'dill', 'keras', 'tensorflow', 'matplotlib', 'scikit-learn'})\n",
      "========================================\n",
      "Recommendations are:  {'pandas', 'pyparsing', 'scipy', 'sklearn', 'cycler', 'jupyter'}\n",
      "========================================\n",
      "Stack is:  frozenset({'pykitti', 'packaging', 'pip', 'keras', 'unrealcv', 'transforms3d', 'pymongo', 'xxhash', 'tensorflow'})\n",
      "========================================\n",
      "Recommendations are:  {'olefile', 'theano', 'sklearn', 'appdirs', 'wcwidth'}\n",
      "========================================\n",
      "Stack is:  frozenset({'tqdm', 'theano', 'keras', 'pygame', 'sgf', 'tensorflow', 'scikit-learn'})\n",
      "========================================\n",
      "Recommendations are:  {'matplotlib', 'cycler', 'seaborn', 'sklearn'}\n",
      "========================================\n",
      "Stack is:  frozenset({'sphinx-gallery', 'nbsphinx', 'keras', 'pillow', 'tensorflow', 'cython', 'ipykernel', 'scikit-learn'})\n",
      "========================================\n",
      "Recommendations are:  {'olefile', 'theano', 'sklearn', 'matplotlib', 'jupyter'}\n",
      "========================================\n",
      "Stack is:  frozenset({'keras', 'pillow', 'dill', 'tensorflow'})\n",
      "========================================\n",
      "Recommendations are:  {'olefile', 'easy-thumbnails', 'djangorestframework', 'sorl-thumbnail', 'markdown', 'django-debug-toolbar'}\n",
      "========================================\n",
      "Stack is:  frozenset({'simplegeneric', 'certifi', 'werkzeug', 'cycler', 'jupyter', 'pytz', 'matplotlib', 'jupyter-console', 'wcwidth', 'imageio', 'olefile', 'pyparsing', 'pillow', 'pathlib2', 'html5lib', 'tqdm', 'singledispatch', 'theano', 'keras', 'moviepy', 'tensorflow', 'backports-shutil-get-terminal-size', 'scandir', 'subprocess32', 'pbr', 'backports-abc'})\n",
      "========================================\n",
      "Recommendations are:  {'ipython'}\n",
      "========================================\n",
      "Stack is:  frozenset({'keras', 'pillow', 'tensorflow'})\n",
      "========================================\n",
      "Recommendations are:  {'olefile', 'djangorestframework', 'markdown', 'dj-database-url', 'django-debug-toolbar', 'django-extensions', 'south'}\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# Let's get top 10 recommendations for our 10 users\n",
    "\n",
    "for stack in x:\n",
    "    # First get the id for the stack\n",
    "    print(\"Stack is: \", stack)\n",
    "    input_stack = map_input_to_package_ids(stack)\n",
    "    scores = model.query(list(input_stack))\n",
    "    ranking = numpy.argsort(scores)[::-1]\n",
    "    top10 = ranking[:10]\n",
    "    recommendations = numpy.array(list(itertools.compress(top10,\n",
    "    [i not in input_stack for i in top10])))\n",
    "    print(\"========================================\")\n",
    "    print(\"Recommendations are: \", set(get_packages_from_id(recommendations)))\n",
    "    print(\"========================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As we can see, the recommendations look to be much better than the previous models. Notice the serendipity of the model, it recommends mostly different packages to the user based on the set of packages which he has used. It doesn't generalize as per the previous models (because we have no CF here and that is because we have no users here) and gives useful rather than popular packages.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO:\n",
    "\n",
    "1. While scoring, we can either use the whole vector (everything you already know the user likes/has consumed), or random sample from it a few times and see whatever items appears in the top of the rankings the most (by doing that you could increase the serendipity of the model)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
